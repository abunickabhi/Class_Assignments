# -*- coding: utf-8 -*-
"""Logistic_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CluQDHbfjzf4N3_gzKnthnT-cLAZ2Xrc
"""

import scipy.io as spio
import numpy as np
mat = spio.loadmat('/home/abunickabhi/Desktop/mnist_all.mat')
import matplotlib.pyplot as plt
from numpy import linalg as la
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier

train3=mat.get('train3')
train3.shape
train=np.reshape(train3[0,:],(-28,28))
train8=mat.get('train8')
train8.shape
train=np.reshape(train8[0,:],(-28,28))

#Pick random numbers from the binary file rows
a=np.random.randint(6131,size=500)
b=np.random.randint(5851,size=500)
a1=train3[a,:]
b1=train8[b,:]
c=np.concatenate((a1,b1),axis=0)
cmean=np.mean(c,axis=0)
c=c-cmean
c=c.astype(np.uint8)
print(c)
cov= np.matmul(c.T,c)
np.shape(cov)
#[x,y]=la.eig(cov)
#x=np.real(x)
#y=np.real(y)
#pca_vec=np.matmul(x.T,c)
#print(pca_vec.shape)
#neigh=KNeighborsClassifier(n_neighbors=2)

#Generating labels and fitting into them
#labels=np.concatenate((np.zeros(500),np.ones(500)),axis=0)
#neigh.fit(c,labels)


#K-NN prediction instead of logistic estimation
#knn_labels=neigh.predict(c.T)

"""### Logistic Regression
$1/(e^{-theta*x} + 1) $
"""

lr=LogisticRegression()